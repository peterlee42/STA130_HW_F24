{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8af6be5",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "1. the difference between Simple Linear Regression and Multiple Linear Regression; and the benefit the latter provides over the former\n",
    "- Simple Linear Regression uses one predictor variable and one outcome variable while Multiple Linear Regression uses two or more predictor variables.\n",
    "- Multiple linear models can consider multiple factors that affect an outcome, so it may be more accurate which makes it more flexible and realistic unline Simple Linear Regression.\n",
    "\n",
    "2. the difference between using a continuous variable and an indicator variable in Simple Linear Regression; and these two linear forms\n",
    "- Continuous: Shows the 'one unit' increase in the predictor variable by using the slope coefficient\n",
    "- Indicator: Numerical variable that only takes two values. It compares the average difference in the outcome variable between the group represented by the indicator variable (0 for base case and 1 for indicator variable).\n",
    "\n",
    "3. the change that happens in the behavior of the model (i.e., the expected nature of the data it models) when a single indicator variable is introduced alongside a continuous variable to create a Multiple Linear Regression; and these two linear forms (i.e., the Simple Linear Regression versus the Multiple Linear Regression)\n",
    "- Your y-intercept will change depending on the indicator variable (whether it is 0 or 1).\n",
    "- This will make there be two parallel lines. The model maintains the same slope for the predictor variable, but for the model will estimate separate intercepts depending on the indicator variable\n",
    "\n",
    "4. the effect of adding an interaction between a continuous and an indicator variable in Multiple Linear Regression models; and this linear form\n",
    "- It will result in two different lines with two different slopes and potentially different intercepts.\n",
    "- The effect of continuous predictor variable on outcome changes based on the indicator variable.\n",
    "\n",
    "5. the behavior of a Multiple Linear Regression model (i.e., the expected nature of the data it models) based only on indicator variables derived from a non-binary categorical variable; this linear form; and the necessarily resulting binary variable encodings it utilizes\n",
    "- With non-binary categories, this will model the mean average outcome for each category of categorical variable. \n",
    "- The model will estimate a separate intercept for each category, which represents the average outcome value for observations in that category.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81857858",
   "metadata": {},
   "source": [
    "## Q2\n",
    "##### GPT: https://chatgpt.com/share/673584cf-0904-8008-ab3f-cf89a9532fb2\n",
    "\n",
    "Explain in your own words (but working with a ChatBot if needed) what the specific (outcome and predictor) variables are for the scenario below; whether or not any meaningful interactions might need to be taken into account when predicting the outcome; and provide the linear forms with and without the potential interactions that might need to be considered\n",
    "\n",
    "Imagine a company that sells sports equipment. The company runs advertising campaigns on TV and online platforms. The effectiveness of the TV ad might depend on the amount spent on online advertising and vice versa, leading to an interaction effect between the two advertising mediums.\n",
    "\n",
    "- Outcome Variable: The effectiveness of the advertising campaign \n",
    "- Predictor Variables: TV advertising spend and online advertising spend\n",
    "\n",
    "1. Explain how to use these two formulas to make predictions of the outcome, and give a high level explaination in general terms of the difference between predictions from the models with and without the interaction\n",
    "- With interaction: $Effectivness = \\beta_0 + \\beta_1TV_i + \\beta_2Online_i + \\beta_3(TV_i \\times Online_i)$\n",
    "    - This will compare the differences in the individual spendings of TV and online.\n",
    "- Without interaction: $Effectiveness = \\beta_0 + \\beta_1TV_i + \\beta_2Online_i$\n",
    "    - This will compare how the impact of TV ads changes with the spendings of online ads and vice versa.\n",
    "\n",
    "2. Explain how to update and use the implied two formulas to make predictions of the outcome if, rather than considering two continuous predictor variables, we instead suppose the advertisement budgets are simply categorized as either \"high\" or \"low\" (binary variables)\n",
    "- With interaction: $Effectivness = \\beta_0 + \\beta_{\\textrm{TV}}1_{[TV_i=\\textrm{\"HIGH\"}]}(TV_i) + \\beta_{\\textrm{Online}}1_{[Online_i=\\textrm{\"HIGH\"}]}(Online_i) + \\beta_{\\textrm{TV change in Online}}1_{[TV_i=\\textrm{\"HIGH\"}]}(TV_i \\times Online_i)$\n",
    "    - Now if we want to look at low budget, then the slope coefficient will be 0 and if we want to see high budget it will be 1. So our y-intercept will be the base case of low budget.\n",
    "- Without interaction: $Effectivness = \\beta_0 + \\beta_{\\textrm{TV}}1_{[TV_i=\\textrm{\"HIGH\"}]}(TV_i) + \\beta_{\\textrm{Onlie}}1_{[Online_i=\\textrm{\"HIGH\"}]}(Online_i)$\n",
    "    - Similar to the other one, our slope coefficient now will account for the average difference when advertising campaign is high budget compared to low budget (which is our intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89de1e29",
   "metadata": {},
   "source": [
    "## Q3\n",
    "##### Use smf to fit multiple linear regression models to the course project dataset from the canadian social connection survey\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc21959",
   "metadata": {},
   "source": [
    "## Q4\n",
    "##### GPT: https://chatgpt.com/share/67363852-d8d8-8008-879c-7cd777dbcb5f\n",
    "\n",
    "##### Explain the apparent contradiction between the factual statements regarding the fit below that \"the model only explains 17.6% of the variability in the data\" while at the same time \"many of the coefficients are larger than 10 while having strong or very strong evidence against the null hypothesis of 'no effect'\"\n",
    "\n",
    "- $R^2$ is shows how well the model explains the variability in the data. A low $R^2$ doesn't necessarily mean the model is useless, it means there other factors can contribute to the variation of this outcome. This omdel suggests that only 17.6% of the variability in the data which is quite low (for example it could be non-linear).\n",
    "\n",
    "- The coeffcients show the relationship between the predictors and the outcome. In this case, it suggests that the predictors have a significant (and meaningful) effect on the outcome.\n",
    "\n",
    "- The apparent contradiction is that a low $R^2$ says that the model does not explain the variability in the data well, but then a large coefficient means that the predictors represent the outcome well which may seem contradictory.\n",
    "\n",
    "- However, this is not neccessarily contradictory as a low $R^2$ tells us the model's capacity to explain the data is low, but the coefficients will tell us that the relationship between the individual predictors and the outcome is strong. This is like saying the relationship between specific predictors and outcomes are strong, but the overall big picture is weak because the data is not explained well enough by the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c59f89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>719</td>\n",
       "      <td>Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>719</td>\n",
       "      <td>DiancieMega Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Unbound</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Dark</td>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>721</td>\n",
       "      <td>Volcanion</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Water</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                   Name   Type 1  Type 2  HP  Attack  Defense  \\\n",
       "0      1              Bulbasaur    Grass  Poison  45      49       49   \n",
       "1      2                Ivysaur    Grass  Poison  60      62       63   \n",
       "2      3               Venusaur    Grass  Poison  80      82       83   \n",
       "3      3  VenusaurMega Venusaur    Grass  Poison  80     100      123   \n",
       "4      4             Charmander     Fire     NaN  39      52       43   \n",
       "..   ...                    ...      ...     ...  ..     ...      ...   \n",
       "795  719                Diancie     Rock   Fairy  50     100      150   \n",
       "796  719    DiancieMega Diancie     Rock   Fairy  50     160      110   \n",
       "797  720    HoopaHoopa Confined  Psychic   Ghost  80     110       60   \n",
       "798  720     HoopaHoopa Unbound  Psychic    Dark  80     160       60   \n",
       "799  721              Volcanion     Fire   Water  80     110      120   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0         65       65     45           1      False  \n",
       "1         80       80     60           1      False  \n",
       "2        100      100     80           1      False  \n",
       "3        122      120     80           1      False  \n",
       "4         60       50     65           1      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "795      100      150     50           6       True  \n",
       "796      160      110    110           6       True  \n",
       "797      150      130     70           6       True  \n",
       "798      170      130     80           6       True  \n",
       "799      130       90     70           6       True  \n",
       "\n",
       "[800 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "# fail https://github.com/KeithGalli/pandas/blob/master/pokemon_data.csv\n",
    "pokeaman = pd.read_csv(url) \n",
    "pokeaman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7c5b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>3.50e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:11:37</td>     <th>  Log-Likelihood:    </th> <td> -3649.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   800</td>      <th>  AIC:               </th> <td>   7323.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   788</td>      <th>  BIC:               </th> <td>   7379.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                       <td>   26.8971</td> <td>    5.246</td> <td>    5.127</td> <td> 0.000</td> <td>   16.599</td> <td>   37.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>              <td>   20.0449</td> <td>    7.821</td> <td>    2.563</td> <td> 0.011</td> <td>    4.692</td> <td>   35.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>              <td>   21.3662</td> <td>    6.998</td> <td>    3.053</td> <td> 0.002</td> <td>    7.629</td> <td>   35.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>              <td>   31.9575</td> <td>    8.235</td> <td>    3.881</td> <td> 0.000</td> <td>   15.793</td> <td>   48.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>              <td>    9.4926</td> <td>    7.883</td> <td>    1.204</td> <td> 0.229</td> <td>   -5.982</td> <td>   24.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>              <td>   22.2693</td> <td>    8.709</td> <td>    2.557</td> <td> 0.011</td> <td>    5.173</td> <td>   39.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                    <td>    0.5634</td> <td>    0.071</td> <td>    7.906</td> <td> 0.000</td> <td>    0.423</td> <td>    0.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.2]</th> <td>   -0.2350</td> <td>    0.101</td> <td>   -2.316</td> <td> 0.021</td> <td>   -0.434</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.3]</th> <td>   -0.3067</td> <td>    0.093</td> <td>   -3.300</td> <td> 0.001</td> <td>   -0.489</td> <td>   -0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.4]</th> <td>   -0.3790</td> <td>    0.105</td> <td>   -3.600</td> <td> 0.000</td> <td>   -0.586</td> <td>   -0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.5]</th> <td>   -0.0484</td> <td>    0.108</td> <td>   -0.447</td> <td> 0.655</td> <td>   -0.261</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.6]</th> <td>   -0.3083</td> <td>    0.112</td> <td>   -2.756</td> <td> 0.006</td> <td>   -0.528</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>337.229</td> <th>  Durbin-Watson:     </th> <td>   1.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2871.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.684</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.649</td>  <th>  Cond. No.          </th> <td>1.40e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                  &        HP        & \\textbf{  R-squared:         } &     0.176   \\\\\n",
       "\\textbf{Model:}                          &       OLS        & \\textbf{  Adj. R-squared:    } &     0.164   \\\\\n",
       "\\textbf{Method:}                         &  Least Squares   & \\textbf{  F-statistic:       } &     15.27   \\\\\n",
       "\\textbf{Date:}                           & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  3.50e-27   \\\\\n",
       "\\textbf{Time:}                           &     20:11:37     & \\textbf{  Log-Likelihood:    } &   -3649.4   \\\\\n",
       "\\textbf{No. Observations:}               &         800      & \\textbf{  AIC:               } &     7323.   \\\\\n",
       "\\textbf{Df Residuals:}                   &         788      & \\textbf{  BIC:               } &     7379.   \\\\\n",
       "\\textbf{Df Model:}                       &          11      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                         & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                       &      26.8971  &        5.246     &     5.127  &         0.000        &       16.599    &       37.195     \\\\\n",
       "\\textbf{C(Generation)[T.2]}              &      20.0449  &        7.821     &     2.563  &         0.011        &        4.692    &       35.398     \\\\\n",
       "\\textbf{C(Generation)[T.3]}              &      21.3662  &        6.998     &     3.053  &         0.002        &        7.629    &       35.103     \\\\\n",
       "\\textbf{C(Generation)[T.4]}              &      31.9575  &        8.235     &     3.881  &         0.000        &       15.793    &       48.122     \\\\\n",
       "\\textbf{C(Generation)[T.5]}              &       9.4926  &        7.883     &     1.204  &         0.229        &       -5.982    &       24.968     \\\\\n",
       "\\textbf{C(Generation)[T.6]}              &      22.2693  &        8.709     &     2.557  &         0.011        &        5.173    &       39.366     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                    &       0.5634  &        0.071     &     7.906  &         0.000        &        0.423    &        0.703     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.2]} &      -0.2350  &        0.101     &    -2.316  &         0.021        &       -0.434    &       -0.036     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.3]} &      -0.3067  &        0.093     &    -3.300  &         0.001        &       -0.489    &       -0.124     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.4]} &      -0.3790  &        0.105     &    -3.600  &         0.000        &       -0.586    &       -0.172     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.5]} &      -0.0484  &        0.108     &    -0.447  &         0.655        &       -0.261    &        0.164     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.6]} &      -0.3083  &        0.112     &    -2.756  &         0.006        &       -0.528    &       -0.089     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 337.229 & \\textbf{  Durbin-Watson:     } &    1.505  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2871.522  \\\\\n",
       "\\textbf{Skew:}          &   1.684 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  11.649 & \\textbf{  Cond. No.          } & 1.40e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.4e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.176\n",
       "Model:                            OLS   Adj. R-squared:                  0.164\n",
       "Method:                 Least Squares   F-statistic:                     15.27\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           3.50e-27\n",
       "Time:                        20:11:37   Log-Likelihood:                -3649.4\n",
       "No. Observations:                 800   AIC:                             7323.\n",
       "Df Residuals:                     788   BIC:                             7379.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "Intercept                          26.8971      5.246      5.127      0.000      16.599      37.195\n",
       "C(Generation)[T.2]                 20.0449      7.821      2.563      0.011       4.692      35.398\n",
       "C(Generation)[T.3]                 21.3662      6.998      3.053      0.002       7.629      35.103\n",
       "C(Generation)[T.4]                 31.9575      8.235      3.881      0.000      15.793      48.122\n",
       "C(Generation)[T.5]                  9.4926      7.883      1.204      0.229      -5.982      24.968\n",
       "C(Generation)[T.6]                 22.2693      8.709      2.557      0.011       5.173      39.366\n",
       "Q(\"Sp. Def\")                        0.5634      0.071      7.906      0.000       0.423       0.703\n",
       "Q(\"Sp. Def\"):C(Generation)[T.2]    -0.2350      0.101     -2.316      0.021      -0.434      -0.036\n",
       "Q(\"Sp. Def\"):C(Generation)[T.3]    -0.3067      0.093     -3.300      0.001      -0.489      -0.124\n",
       "Q(\"Sp. Def\"):C(Generation)[T.4]    -0.3790      0.105     -3.600      0.000      -0.586      -0.172\n",
       "Q(\"Sp. Def\"):C(Generation)[T.5]    -0.0484      0.108     -0.447      0.655      -0.261       0.164\n",
       "Q(\"Sp. Def\"):C(Generation)[T.6]    -0.3083      0.112     -2.756      0.006      -0.528      -0.089\n",
       "==============================================================================\n",
       "Omnibus:                      337.229   Durbin-Watson:                   1.505\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2871.522\n",
       "Skew:                           1.684   Prob(JB):                         0.00\n",
       "Kurtosis:                      11.649   Cond. No.                     1.40e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model1_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation) + Q(\"Sp. Def\"):C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") * C(Generation)', data=pokeaman)\n",
    "\n",
    "model2_fit = model2_spec.fit()\n",
    "model2_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bc8cf2",
   "metadata": {},
   "source": [
    "## Q5\n",
    "\n",
    "##### GPT: https://chatgpt.com/share/67364750-2564-8008-9cc4-f381c31d71b4\n",
    "\n",
    "##### Discuss the following (five cells of) code and results with a ChatBot and based on the understanding you arrive at in this conversation explain what the following (five cells of) are illustrating\n",
    "\n",
    "1. The code changes all missing values to \"None\" and splits the pokeaman dataset into two halves (training and testing)\n",
    "2. Performs a linear regression analysis on pokeaman_train using OLS (ordinary least squares) method to model the relationship between HP and two predictors attack and defense. It fits the model to be able to get calculate the slope coefficients for the two predictors and then gives summary  of fitted model's stats.\n",
    "3. First, it uses the fitted model to predict values for HP in data values in pokeaman_test. Then it extracts the actual HP values. Then it outputs in-sample $R^2$, which is the value based in how well the model fits the training data, and out-of-sample $R^2$ which shows how well the training data predicts new data. Since they are similar, we can say that the model generalizes well to the test data.\n",
    "4. Defines a high dimensional  linear regression model that has 6 variable interactions (attack, defense, speed, Sp. Defense, Sp. Attack). This will reveal the strenght and significance of each predictor and their interaction in explaining variations in HP\n",
    "5. This evaluates how well the model fits the training data of model4_fit (in sample $R^2$) and how well the predicted values for the testing data compare to the actual HP values (out of sample $R^2$). Since there is a significant gap between the two values, we can say there is overfitting due to its complexity. This means it would perform well on training data, but not well when predicting new, unseen values using testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64967274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>338</td>\n",
       "      <td>Solrock</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>70</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Charizard</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Flying</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>109</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>224</td>\n",
       "      <td>Octillery</td>\n",
       "      <td>Water</td>\n",
       "      <td>None</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>600</td>\n",
       "      <td>Klang</td>\n",
       "      <td>Steel</td>\n",
       "      <td>None</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>265</td>\n",
       "      <td>Wurmple</td>\n",
       "      <td>Bug</td>\n",
       "      <td>None</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>471</td>\n",
       "      <td>Glaceon</td>\n",
       "      <td>Ice</td>\n",
       "      <td>None</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>225</td>\n",
       "      <td>Delibird</td>\n",
       "      <td>Ice</td>\n",
       "      <td>Flying</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>109</td>\n",
       "      <td>Koffing</td>\n",
       "      <td>Poison</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>373</td>\n",
       "      <td>SalamenceMega Salamence</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>Flying</td>\n",
       "      <td>95</td>\n",
       "      <td>145</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                     Name   Type 1   Type 2  HP  Attack  Defense  \\\n",
       "370  338                  Solrock     Rock  Psychic  70      95       85   \n",
       "6      6                Charizard     Fire   Flying  78      84       78   \n",
       "242  224                Octillery    Water     None  75     105       75   \n",
       "661  600                    Klang    Steel     None  60      80       95   \n",
       "288  265                  Wurmple      Bug     None  45      45       35   \n",
       "..   ...                      ...      ...      ...  ..     ...      ...   \n",
       "522  471                  Glaceon      Ice     None  65      60      110   \n",
       "243  225                 Delibird      Ice   Flying  45      55       45   \n",
       "797  720      HoopaHoopa Confined  Psychic    Ghost  80     110       60   \n",
       "117  109                  Koffing   Poison     None  40      65       95   \n",
       "409  373  SalamenceMega Salamence   Dragon   Flying  95     145      130   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "370       55       65     70           3      False  \n",
       "6        109       85    100           1      False  \n",
       "242      105       75     45           2      False  \n",
       "661       70       85     50           5      False  \n",
       "288       20       30     20           3      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "522      130       95     65           4      False  \n",
       "243       65       45     75           2      False  \n",
       "797      150      130     70           6       True  \n",
       "117       60       45     35           1      False  \n",
       "409      120       90    120           3      False  \n",
       "\n",
       "[400 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fifty_fifty_split_size = int(pokeaman.shape[0]*0.5)\n",
    "\n",
    "# Replace \"NaN\" (in the \"Type 2\" column with \"None\")\n",
    "pokeaman.fillna('None', inplace=True)\n",
    "\n",
    "np.random.seed(130)\n",
    "pokeaman_train,pokeaman_test = \\\n",
    "  train_test_split(pokeaman, train_size=fifty_fifty_split_size)\n",
    "pokeaman_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c04cd272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:11:37</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     20:11:37     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        20:11:37   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spec3 = smf.ols(formula='HP ~ Attack + Defense', \n",
    "                      data=pokeaman_train)\n",
    "model3_fit = model_spec3.fit()\n",
    "model3_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd9ea275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.14771558304519894\n",
      "'Out of sample' R-squared: 0.21208501873920738\n"
     ]
    }
   ],
   "source": [
    "yhat_model3 = model3_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model3_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model3)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "110e2d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.23e-21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:11:37</td>     <th>  Log-Likelihood:    </th> <td> -1738.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3603.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   337</td>      <th>  BIC:               </th> <td>   3855.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    62</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                  <td></td>                                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                        <td>  521.5715</td> <td>  130.273</td> <td>    4.004</td> <td> 0.000</td> <td>  265.322</td> <td>  777.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>                                                <td>   -6.1179</td> <td>    2.846</td> <td>   -2.150</td> <td> 0.032</td> <td>  -11.716</td> <td>   -0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                                           <td>   -8.1938</td> <td>    2.329</td> <td>   -3.518</td> <td> 0.000</td> <td>  -12.775</td> <td>   -3.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]</th>                                         <td>-1224.9610</td> <td>  545.105</td> <td>   -2.247</td> <td> 0.025</td> <td>-2297.199</td> <td> -152.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                                                          <td>   -6.1989</td> <td>    2.174</td> <td>   -2.851</td> <td> 0.005</td> <td>  -10.475</td> <td>   -1.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]</th>                                        <td> -102.4030</td> <td>   96.565</td> <td>   -1.060</td> <td> 0.290</td> <td> -292.350</td> <td>   87.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense</th>                                                   <td>    0.0985</td> <td>    0.033</td> <td>    2.982</td> <td> 0.003</td> <td>    0.034</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]</th>                                 <td>   14.6361</td> <td>    6.267</td> <td>    2.336</td> <td> 0.020</td> <td>    2.310</td> <td>   26.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                                            <td>   -7.2261</td> <td>    2.178</td> <td>   -3.318</td> <td> 0.001</td> <td>  -11.511</td> <td>   -2.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]</th>                                          <td>  704.8798</td> <td>  337.855</td> <td>    2.086</td> <td> 0.038</td> <td>   40.309</td> <td> 1369.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                                                     <td>    0.1264</td> <td>    0.038</td> <td>    3.351</td> <td> 0.001</td> <td>    0.052</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]</th>                                   <td>    5.8648</td> <td>    2.692</td> <td>    2.179</td> <td> 0.030</td> <td>    0.570</td> <td>   11.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed</th>                                                    <td>    0.1026</td> <td>    0.039</td> <td>    2.634</td> <td> 0.009</td> <td>    0.026</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]</th>                                  <td>   -6.9266</td> <td>    3.465</td> <td>   -1.999</td> <td> 0.046</td> <td>  -13.742</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed</th>                                             <td>   -0.0016</td> <td>    0.001</td> <td>   -2.837</td> <td> 0.005</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]</th>                           <td>   -0.0743</td> <td>    0.030</td> <td>   -2.477</td> <td> 0.014</td> <td>   -0.133</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                                                     <td>   -5.3982</td> <td>    1.938</td> <td>   -2.785</td> <td> 0.006</td> <td>   -9.211</td> <td>   -1.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\")</th>                                   <td> -282.2496</td> <td>  126.835</td> <td>   -2.225</td> <td> 0.027</td> <td> -531.738</td> <td>  -32.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                                              <td>    0.1094</td> <td>    0.034</td> <td>    3.233</td> <td> 0.001</td> <td>    0.043</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\")</th>                            <td>   12.6503</td> <td>    5.851</td> <td>    2.162</td> <td> 0.031</td> <td>    1.141</td> <td>   24.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\")</th>                                             <td>    0.0628</td> <td>    0.028</td> <td>    2.247</td> <td> 0.025</td> <td>    0.008</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                           <td>    3.3949</td> <td>    1.783</td> <td>    1.904</td> <td> 0.058</td> <td>   -0.112</td> <td>    6.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\")</th>                                      <td>   -0.0012</td> <td>    0.000</td> <td>   -2.730</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                    <td>   -0.1456</td> <td>    0.065</td> <td>   -2.253</td> <td> 0.025</td> <td>   -0.273</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                                               <td>    0.0624</td> <td>    0.031</td> <td>    2.027</td> <td> 0.043</td> <td>    0.002</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                             <td>   -3.2219</td> <td>    1.983</td> <td>   -1.625</td> <td> 0.105</td> <td>   -7.122</td> <td>    0.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>                                        <td>   -0.0014</td> <td>    0.001</td> <td>   -2.732</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                      <td>   -0.0695</td> <td>    0.033</td> <td>   -2.100</td> <td> 0.036</td> <td>   -0.135</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\")</th>                                       <td>   -0.0008</td> <td>    0.000</td> <td>   -1.743</td> <td> 0.082</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                     <td>    0.0334</td> <td>    0.021</td> <td>    1.569</td> <td> 0.117</td> <td>   -0.008</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\")</th>                                <td> 1.629e-05</td> <td> 6.92e-06</td> <td>    2.355</td> <td> 0.019</td> <td> 2.68e-06</td> <td> 2.99e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>              <td>    0.0008</td> <td>    0.000</td> <td>    2.433</td> <td> 0.015</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                                                     <td>   -8.3636</td> <td>    2.346</td> <td>   -3.565</td> <td> 0.000</td> <td>  -12.978</td> <td>   -3.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Atk\")</th>                                   <td>  850.5436</td> <td>  385.064</td> <td>    2.209</td> <td> 0.028</td> <td>   93.112</td> <td> 1607.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                                              <td>    0.1388</td> <td>    0.040</td> <td>    3.500</td> <td> 0.001</td> <td>    0.061</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Atk\")</th>                            <td>    2.1809</td> <td>    1.136</td> <td>    1.920</td> <td> 0.056</td> <td>   -0.054</td> <td>    4.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Atk\")</th>                                             <td>    0.0831</td> <td>    0.038</td> <td>    2.162</td> <td> 0.031</td> <td>    0.007</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                           <td>   -7.3121</td> <td>    3.376</td> <td>   -2.166</td> <td> 0.031</td> <td>  -13.953</td> <td>   -0.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Atk\")</th>                                      <td>   -0.0014</td> <td>    0.001</td> <td>   -2.480</td> <td> 0.014</td> <td>   -0.003</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                    <td>   -0.0434</td> <td>    0.022</td> <td>   -2.010</td> <td> 0.045</td> <td>   -0.086</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                                               <td>    0.1011</td> <td>    0.035</td> <td>    2.872</td> <td> 0.004</td> <td>    0.032</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                             <td>  -12.6343</td> <td>    5.613</td> <td>   -2.251</td> <td> 0.025</td> <td>  -23.674</td> <td>   -1.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>                                        <td>   -0.0018</td> <td>    0.001</td> <td>   -3.102</td> <td> 0.002</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                      <td>    0.0151</td> <td>    0.009</td> <td>    1.609</td> <td> 0.109</td> <td>   -0.003</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Atk\")</th>                                       <td>   -0.0012</td> <td>    0.001</td> <td>   -1.860</td> <td> 0.064</td> <td>   -0.002</td> <td> 6.62e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                     <td>    0.1210</td> <td>    0.054</td> <td>    2.260</td> <td> 0.024</td> <td>    0.016</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Atk\")</th>                                <td> 2.125e-05</td> <td>  9.1e-06</td> <td>    2.334</td> <td> 0.020</td> <td> 3.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>              <td> 6.438e-06</td> <td> 7.69e-05</td> <td>    0.084</td> <td> 0.933</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                        <td>    0.1265</td> <td>    0.033</td> <td>    3.821</td> <td> 0.000</td> <td>    0.061</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                      <td>   -5.0544</td> <td>    2.506</td> <td>   -2.017</td> <td> 0.044</td> <td>   -9.983</td> <td>   -0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                 <td>   -0.0021</td> <td>    0.001</td> <td>   -3.606</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>               <td>   -0.0346</td> <td>    0.017</td> <td>   -1.992</td> <td> 0.047</td> <td>   -0.069</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                <td>   -0.0012</td> <td>    0.000</td> <td>   -2.406</td> <td> 0.017</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0446</td> <td>    0.025</td> <td>    1.794</td> <td> 0.074</td> <td>   -0.004</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                         <td> 1.973e-05</td> <td> 7.28e-06</td> <td>    2.710</td> <td> 0.007</td> <td> 5.41e-06</td> <td>  3.4e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>    0.0005</td> <td>    0.000</td> <td>    1.957</td> <td> 0.051</td> <td>-2.56e-06</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                  <td>   -0.0013</td> <td>    0.000</td> <td>   -2.740</td> <td> 0.006</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                <td>    0.0841</td> <td>    0.040</td> <td>    2.125</td> <td> 0.034</td> <td>    0.006</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                           <td> 2.379e-05</td> <td> 7.85e-06</td> <td>    3.030</td> <td> 0.003</td> <td> 8.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>         <td> 2.864e-05</td> <td> 7.73e-05</td> <td>    0.370</td> <td> 0.711</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                          <td> 1.284e-05</td> <td> 7.46e-06</td> <td>    1.721</td> <td> 0.086</td> <td>-1.83e-06</td> <td> 2.75e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0008</td> <td>    0.000</td> <td>   -2.085</td> <td> 0.038</td> <td>   -0.002</td> <td>-4.68e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                   <td> -2.53e-07</td> <td>  1.1e-07</td> <td>   -2.292</td> <td> 0.023</td> <td> -4.7e-07</td> <td>-3.59e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>-1.425e-06</td> <td> 1.14e-06</td> <td>   -1.249</td> <td> 0.212</td> <td>-3.67e-06</td> <td> 8.19e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.2e+16. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                                   &        HP        & \\textbf{  R-squared:         } &     0.467   \\\\\n",
       "\\textbf{Model:}                                                           &       OLS        & \\textbf{  Adj. R-squared:    } &     0.369   \\\\\n",
       "\\textbf{Method:}                                                          &  Least Squares   & \\textbf{  F-statistic:       } &     4.764   \\\\\n",
       "\\textbf{Date:}                                                            & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.23e-21   \\\\\n",
       "\\textbf{Time:}                                                            &     20:11:37     & \\textbf{  Log-Likelihood:    } &   -1738.6   \\\\\n",
       "\\textbf{No. Observations:}                                                &         400      & \\textbf{  AIC:               } &     3603.   \\\\\n",
       "\\textbf{Df Residuals:}                                                    &         337      & \\textbf{  BIC:               } &     3855.   \\\\\n",
       "\\textbf{Df Model:}                                                        &          62      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                                                 &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                                        &     521.5715  &      130.273     &     4.004  &         0.000        &      265.322    &      777.821     \\\\\n",
       "\\textbf{Legendary[T.True]}                                                &      -6.1179  &        2.846     &    -2.150  &         0.032        &      -11.716    &       -0.520     \\\\\n",
       "\\textbf{Attack}                                                           &      -8.1938  &        2.329     &    -3.518  &         0.000        &      -12.775    &       -3.612     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]}                                         &   -1224.9610  &      545.105     &    -2.247  &         0.025        &    -2297.199    &     -152.723     \\\\\n",
       "\\textbf{Defense}                                                          &      -6.1989  &        2.174     &    -2.851  &         0.005        &      -10.475    &       -1.923     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]}                                        &    -102.4030  &       96.565     &    -1.060  &         0.290        &     -292.350    &       87.544     \\\\\n",
       "\\textbf{Attack:Defense}                                                   &       0.0985  &        0.033     &     2.982  &         0.003        &        0.034    &        0.164     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]}                                 &      14.6361  &        6.267     &     2.336  &         0.020        &        2.310    &       26.963     \\\\\n",
       "\\textbf{Speed}                                                            &      -7.2261  &        2.178     &    -3.318  &         0.001        &      -11.511    &       -2.942     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]}                                          &     704.8798  &      337.855     &     2.086  &         0.038        &       40.309    &     1369.450     \\\\\n",
       "\\textbf{Attack:Speed}                                                     &       0.1264  &        0.038     &     3.351  &         0.001        &        0.052    &        0.201     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]}                                   &       5.8648  &        2.692     &     2.179  &         0.030        &        0.570    &       11.160     \\\\\n",
       "\\textbf{Defense:Speed}                                                    &       0.1026  &        0.039     &     2.634  &         0.009        &        0.026    &        0.179     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]}                                  &      -6.9266  &        3.465     &    -1.999  &         0.046        &      -13.742    &       -0.111     \\\\\n",
       "\\textbf{Attack:Defense:Speed}                                             &      -0.0016  &        0.001     &    -2.837  &         0.005        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]}                           &      -0.0743  &        0.030     &    -2.477  &         0.014        &       -0.133    &       -0.015     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                                                     &      -5.3982  &        1.938     &    -2.785  &         0.006        &       -9.211    &       -1.586     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\")}                                   &    -282.2496  &      126.835     &    -2.225  &         0.027        &     -531.738    &      -32.761     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                                              &       0.1094  &        0.034     &     3.233  &         0.001        &        0.043    &        0.176     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\")}                            &      12.6503  &        5.851     &     2.162  &         0.031        &        1.141    &       24.160     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\")}                                             &       0.0628  &        0.028     &     2.247  &         0.025        &        0.008    &        0.118     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\")}                           &       3.3949  &        1.783     &     1.904  &         0.058        &       -0.112    &        6.902     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\")}                                      &      -0.0012  &        0.000     &    -2.730  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")}                    &      -0.1456  &        0.065     &    -2.253  &         0.025        &       -0.273    &       -0.018     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                                               &       0.0624  &        0.031     &     2.027  &         0.043        &        0.002    &        0.123     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\")}                             &      -3.2219  &        1.983     &    -1.625  &         0.105        &       -7.122    &        0.678     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}                                        &      -0.0014  &        0.001     &    -2.732  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                      &      -0.0695  &        0.033     &    -2.100  &         0.036        &       -0.135    &       -0.004     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\")}                                       &      -0.0008  &        0.000     &    -1.743  &         0.082        &       -0.002    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                     &       0.0334  &        0.021     &     1.569  &         0.117        &       -0.008    &        0.075     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\")}                                &    1.629e-05  &     6.92e-06     &     2.355  &         0.019        &     2.68e-06    &     2.99e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}              &       0.0008  &        0.000     &     2.433  &         0.015        &        0.000    &        0.001     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                                                     &      -8.3636  &        2.346     &    -3.565  &         0.000        &      -12.978    &       -3.749     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Atk\")}                                   &     850.5436  &      385.064     &     2.209  &         0.028        &       93.112    &     1607.975     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                                              &       0.1388  &        0.040     &     3.500  &         0.001        &        0.061    &        0.217     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Atk\")}                            &       2.1809  &        1.136     &     1.920  &         0.056        &       -0.054    &        4.416     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Atk\")}                                             &       0.0831  &        0.038     &     2.162  &         0.031        &        0.007    &        0.159     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                           &      -7.3121  &        3.376     &    -2.166  &         0.031        &      -13.953    &       -0.671     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Atk\")}                                      &      -0.0014  &        0.001     &    -2.480  &         0.014        &       -0.003    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                    &      -0.0434  &        0.022     &    -2.010  &         0.045        &       -0.086    &       -0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                                               &       0.1011  &        0.035     &     2.872  &         0.004        &        0.032    &        0.170     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                             &     -12.6343  &        5.613     &    -2.251  &         0.025        &      -23.674    &       -1.594     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}                                        &      -0.0018  &        0.001     &    -3.102  &         0.002        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                      &       0.0151  &        0.009     &     1.609  &         0.109        &       -0.003    &        0.034     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Atk\")}                                       &      -0.0012  &        0.001     &    -1.860  &         0.064        &       -0.002    &     6.62e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                     &       0.1210  &        0.054     &     2.260  &         0.024        &        0.016    &        0.226     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Atk\")}                                &    2.125e-05  &      9.1e-06     &     2.334  &         0.020        &     3.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}              &    6.438e-06  &     7.69e-05     &     0.084  &         0.933        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                        &       0.1265  &        0.033     &     3.821  &         0.000        &        0.061    &        0.192     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                      &      -5.0544  &        2.506     &    -2.017  &         0.044        &       -9.983    &       -0.126     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                 &      -0.0021  &        0.001     &    -3.606  &         0.000        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}               &      -0.0346  &        0.017     &    -1.992  &         0.047        &       -0.069    &       -0.000     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                &      -0.0012  &        0.000     &    -2.406  &         0.017        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0446  &        0.025     &     1.794  &         0.074        &       -0.004    &        0.093     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                         &    1.973e-05  &     7.28e-06     &     2.710  &         0.007        &     5.41e-06    &      3.4e-05     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &       0.0005  &        0.000     &     1.957  &         0.051        &    -2.56e-06    &        0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                  &      -0.0013  &        0.000     &    -2.740  &         0.006        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                &       0.0841  &        0.040     &     2.125  &         0.034        &        0.006    &        0.162     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                           &    2.379e-05  &     7.85e-06     &     3.030  &         0.003        &     8.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}         &    2.864e-05  &     7.73e-05     &     0.370  &         0.711        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                          &    1.284e-05  &     7.46e-06     &     1.721  &         0.086        &    -1.83e-06    &     2.75e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0008  &        0.000     &    -2.085  &         0.038        &       -0.002    &    -4.68e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                   &    -2.53e-07  &      1.1e-07     &    -2.292  &         0.023        &     -4.7e-07    &    -3.59e-08     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &   -1.425e-06  &     1.14e-06     &    -1.249  &         0.212        &    -3.67e-06    &     8.19e-07     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.664  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.2e+16. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.467\n",
       "Model:                            OLS   Adj. R-squared:                  0.369\n",
       "Method:                 Least Squares   F-statistic:                     4.764\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           4.23e-21\n",
       "Time:                        20:11:37   Log-Likelihood:                -1738.6\n",
       "No. Observations:                 400   AIC:                             3603.\n",
       "Df Residuals:                     337   BIC:                             3855.\n",
       "Df Model:                          62                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================================================\n",
       "                                                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                          521.5715    130.273      4.004      0.000     265.322     777.821\n",
       "Legendary[T.True]                                                   -6.1179      2.846     -2.150      0.032     -11.716      -0.520\n",
       "Attack                                                              -8.1938      2.329     -3.518      0.000     -12.775      -3.612\n",
       "Attack:Legendary[T.True]                                         -1224.9610    545.105     -2.247      0.025   -2297.199    -152.723\n",
       "Defense                                                             -6.1989      2.174     -2.851      0.005     -10.475      -1.923\n",
       "Defense:Legendary[T.True]                                         -102.4030     96.565     -1.060      0.290    -292.350      87.544\n",
       "Attack:Defense                                                       0.0985      0.033      2.982      0.003       0.034       0.164\n",
       "Attack:Defense:Legendary[T.True]                                    14.6361      6.267      2.336      0.020       2.310      26.963\n",
       "Speed                                                               -7.2261      2.178     -3.318      0.001     -11.511      -2.942\n",
       "Speed:Legendary[T.True]                                            704.8798    337.855      2.086      0.038      40.309    1369.450\n",
       "Attack:Speed                                                         0.1264      0.038      3.351      0.001       0.052       0.201\n",
       "Attack:Speed:Legendary[T.True]                                       5.8648      2.692      2.179      0.030       0.570      11.160\n",
       "Defense:Speed                                                        0.1026      0.039      2.634      0.009       0.026       0.179\n",
       "Defense:Speed:Legendary[T.True]                                     -6.9266      3.465     -1.999      0.046     -13.742      -0.111\n",
       "Attack:Defense:Speed                                                -0.0016      0.001     -2.837      0.005      -0.003      -0.001\n",
       "Attack:Defense:Speed:Legendary[T.True]                              -0.0743      0.030     -2.477      0.014      -0.133      -0.015\n",
       "Q(\"Sp. Def\")                                                        -5.3982      1.938     -2.785      0.006      -9.211      -1.586\n",
       "Legendary[T.True]:Q(\"Sp. Def\")                                    -282.2496    126.835     -2.225      0.027    -531.738     -32.761\n",
       "Attack:Q(\"Sp. Def\")                                                  0.1094      0.034      3.233      0.001       0.043       0.176\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\")                               12.6503      5.851      2.162      0.031       1.141      24.160\n",
       "Defense:Q(\"Sp. Def\")                                                 0.0628      0.028      2.247      0.025       0.008       0.118\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\")                               3.3949      1.783      1.904      0.058      -0.112       6.902\n",
       "Attack:Defense:Q(\"Sp. Def\")                                         -0.0012      0.000     -2.730      0.007      -0.002      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")                       -0.1456      0.065     -2.253      0.025      -0.273      -0.018\n",
       "Speed:Q(\"Sp. Def\")                                                   0.0624      0.031      2.027      0.043       0.002       0.123\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\")                                -3.2219      1.983     -1.625      0.105      -7.122       0.678\n",
       "Attack:Speed:Q(\"Sp. Def\")                                           -0.0014      0.001     -2.732      0.007      -0.002      -0.000\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         -0.0695      0.033     -2.100      0.036      -0.135      -0.004\n",
       "Defense:Speed:Q(\"Sp. Def\")                                          -0.0008      0.000     -1.743      0.082      -0.002       0.000\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         0.0334      0.021      1.569      0.117      -0.008       0.075\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\")                                 1.629e-05   6.92e-06      2.355      0.019    2.68e-06    2.99e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                  0.0008      0.000      2.433      0.015       0.000       0.001\n",
       "Q(\"Sp. Atk\")                                                        -8.3636      2.346     -3.565      0.000     -12.978      -3.749\n",
       "Legendary[T.True]:Q(\"Sp. Atk\")                                     850.5436    385.064      2.209      0.028      93.112    1607.975\n",
       "Attack:Q(\"Sp. Atk\")                                                  0.1388      0.040      3.500      0.001       0.061       0.217\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Atk\")                                2.1809      1.136      1.920      0.056      -0.054       4.416\n",
       "Defense:Q(\"Sp. Atk\")                                                 0.0831      0.038      2.162      0.031       0.007       0.159\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Atk\")                              -7.3121      3.376     -2.166      0.031     -13.953      -0.671\n",
       "Attack:Defense:Q(\"Sp. Atk\")                                         -0.0014      0.001     -2.480      0.014      -0.003      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")                       -0.0434      0.022     -2.010      0.045      -0.086      -0.001\n",
       "Speed:Q(\"Sp. Atk\")                                                   0.1011      0.035      2.872      0.004       0.032       0.170\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Atk\")                               -12.6343      5.613     -2.251      0.025     -23.674      -1.594\n",
       "Attack:Speed:Q(\"Sp. Atk\")                                           -0.0018      0.001     -3.102      0.002      -0.003      -0.001\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                          0.0151      0.009      1.609      0.109      -0.003       0.034\n",
       "Defense:Speed:Q(\"Sp. Atk\")                                          -0.0012      0.001     -1.860      0.064      -0.002    6.62e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                         0.1210      0.054      2.260      0.024       0.016       0.226\n",
       "Attack:Defense:Speed:Q(\"Sp. Atk\")                                 2.125e-05    9.1e-06      2.334      0.020    3.34e-06    3.92e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")               6.438e-06   7.69e-05      0.084      0.933      -0.000       0.000\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                            0.1265      0.033      3.821      0.000       0.061       0.192\n",
       "Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                         -5.0544      2.506     -2.017      0.044      -9.983      -0.126\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                    -0.0021      0.001     -3.606      0.000      -0.003      -0.001\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  -0.0346      0.017     -1.992      0.047      -0.069      -0.000\n",
       "Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                   -0.0012      0.000     -2.406      0.017      -0.002      -0.000\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0446      0.025      1.794      0.074      -0.004       0.093\n",
       "Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                          1.973e-05   7.28e-06      2.710      0.007    5.41e-06     3.4e-05\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           0.0005      0.000      1.957      0.051   -2.56e-06       0.001\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                     -0.0013      0.000     -2.740      0.006      -0.002      -0.000\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    0.0841      0.040      2.125      0.034       0.006       0.162\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                            2.379e-05   7.85e-06      3.030      0.003    8.34e-06    3.92e-05\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          2.864e-05   7.73e-05      0.370      0.711      -0.000       0.000\n",
       "Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                           1.284e-05   7.46e-06      1.721      0.086   -1.83e-06    2.75e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0008      0.000     -2.085      0.038      -0.002   -4.68e-05\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    -2.53e-07    1.1e-07     -2.292      0.023    -4.7e-07   -3.59e-08\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\") -1.425e-06   1.14e-06     -1.249      0.212   -3.67e-06    8.19e-07\n",
       "==============================================================================\n",
       "Omnibus:                      214.307   Durbin-Watson:                   1.992\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2354.664\n",
       "Skew:                           2.026   Prob(JB):                         0.00\n",
       "Kurtosis:                      14.174   Cond. No.                     1.20e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.2e+16. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form = 'HP ~ Attack * Defense * Speed * Legendary'\n",
    "model4_linear_form += ' * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "# DO NOT try adding '* C(Generation) * C(Q(\"Type 1\")) * C(Q(\"Type 2\"))'\n",
    "# That's 6*18*19 = 6*18*19 possible interaction combinations...\n",
    "# ...a huge number that will blow up your computer\n",
    "\n",
    "model4_spec = smf.ols(formula=model4_linear_form, data=pokeaman_train)\n",
    "model4_fit = model4_spec.fit()\n",
    "model4_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b135196c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.46709442115833855\n",
      "'Out of sample' R-squared: 0.002485342598992873\n"
     ]
    }
   ],
   "source": [
    "yhat_model4 = model4_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model4_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model4)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e1b06a",
   "metadata": {},
   "source": [
    "## Q6\n",
    "\n",
    "##### GPT: https://chatgpt.com/share/673656a1-2828-8008-9268-225b2a976886\n",
    "\n",
    "##### Work with a ChatBot to understand how the model4_linear_form (linear form specification of model4) creates new predictor variables as the columns of the so-called \"design matrix\" model4_spec.exog (model4_spec.exog.shape) used to predict the outcome variable model4_spec.endog and why the so-called multicollinearity in this \"design matrix\" (observed in np.corrcoef(model4_spec.exog)) contribues to the lack of \"out of sample\" generalization of predictions from model4_fit; then, explain this consisely in your own works\n",
    "\n",
    "- With that many interactions, the design matrix will expand since it generates multiple predictor combinations which captures complex relationships in the data\n",
    "- However, the new predictor variables that are made have high correlation which causes multicollinearity. High correlations will cause the model to focus on patterns that may or may not exist in the new data since it is difficult for the model to understand the impact that each individual predictor has on the outcome. Highly correlated predictors contain similar information, so small changes in data will make significant change in the coefficients which leads the model to have a hard time deciding how much weight to give each predictor. This makes it so that the model holds for the training data but not neccessarily for the testing data. In other words, the model will pick up patterns in the training data that may not hold for the testing data, which makes it fail to generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "568360a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:11:37</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     20:11:37     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        20:11:37   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Cond. No.\" WAS 343.0 WITHOUT to centering and scaling\n",
    "model3_fit.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e06fd858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:11:37</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>              <td>   69.3025</td> <td>    1.186</td> <td>   58.439</td> <td> 0.000</td> <td>   66.971</td> <td>   71.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Attack))</th>  <td>    8.1099</td> <td>    1.340</td> <td>    6.051</td> <td> 0.000</td> <td>    5.475</td> <td>   10.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Defense))</th> <td>    2.9496</td> <td>    1.340</td> <td>    2.201</td> <td> 0.028</td> <td>    0.315</td> <td>    5.585</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    1.66</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}         &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}                &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}                  & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}                  &     20:11:37     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:}      &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}          &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}              &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}              &      69.3025  &        1.186     &    58.439  &         0.000        &       66.971    &       71.634     \\\\\n",
       "\\textbf{scale(center(Attack))}  &       8.1099  &        1.340     &     6.051  &         0.000        &        5.475    &       10.745     \\\\\n",
       "\\textbf{scale(center(Defense))} &       2.9496  &        1.340     &     2.201  &         0.028        &        0.315    &        5.585     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     1.66  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        20:11:37   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "Intercept                 69.3025      1.186     58.439      0.000      66.971      71.634\n",
       "scale(center(Attack))      8.1099      1.340      6.051      0.000       5.475      10.745\n",
       "scale(center(Defense))     2.9496      1.340      2.201      0.028       0.315       5.585\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         1.66\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from patsy import center, scale\n",
    "\n",
    "model3_linear_form_center_scale = \\\n",
    "  'HP ~ scale(center(Attack)) + scale(center(Defense))' \n",
    "model_spec3_center_scale = smf.ols(formula=model3_linear_form_center_scale,\n",
    "                                   data=pokeaman_train)\n",
    "model3_center_scale_fit = model_spec3_center_scale.fit()\n",
    "model3_center_scale_fit.summary()\n",
    "# \"Cond. No.\" is NOW 1.66 due to centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcde57cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.54e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.663  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.54e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Defense))'\n",
    "model4_linear_form_CS += ' * scale(center(Speed)) * Legendary' \n",
    "model4_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# Legendary is an indicator, so we don't center and scale that\n",
    "\n",
    "model4_CS_spec = smf.ols(formula=model4_linear_form_CS, data=pokeaman_train)\n",
    "model4_CS_fit = model4_CS_spec.fit()\n",
    "model4_CS_fit.summary().tables[-1]  # Cond. No. is 2,250,000,000,000,000\n",
    "\n",
    "# The condition number is still bad even after centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "017cc067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.664  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just as the condition number was very bad to start with\n",
    "model4_fit.summary().tables[-1]  # Cond. No. is 12,000,000,000,000,000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf0631e",
   "metadata": {},
   "source": [
    "## Q7\n",
    "\n",
    "##### GPT: https://chatgpt.com/share/67365f1e-e314-8008-b478-e8fe8e1835c2\n",
    "\n",
    "### the rationale and principles by which:\n",
    "##### model5_linear_form is extended and developed from model3_fit and model4_fit\n",
    "- model3_fit is simple, and so model 5 introduces more predictor variables to include more features that impact HP\n",
    "- Again, model4_fit considered certain predictors, but model 5 added 3 more. Since model4_fit was really complex, we focus on adding these main features instead of having a bunch of interactions which helps us give a balance between complexity and interpretability which was hard for model_4 to do.\n",
    "- We see that multicollinearity is not an issue by in and out of sample $R^2$\n",
    "\n",
    "##### model6_linear_form is extended and developed from model5_linear_form\n",
    "- We simplified this by removing Defense and Legendary from the list of predictors, mainly because the p-value was too high showing that we do not have enough evidence to support that it is a significant factor in HP\n",
    "- In model 5, we also see that the categories do not have good evidence in most of the interactions.\n",
    "- We introduce indicator variables that we think will have a reasonable affect on HP. Instead of using complex interactions, we use indicator variables to focus on categories that we think may have an impact on HP\n",
    "- Again, we see that multicollinearity is not an issue by in and out of sample $R^2$\n",
    "\n",
    "##### model7_linear_form is extended and developed from model6_linear_form\n",
    "- In model 7 introduce interaction terms of the continuous predictors. This gives us a deeper understanding of the complex relationships between these predictors. It helps us understand how the interactions influence the outcome rather than just the individual predictors.\n",
    "- The indicator variables are kept.\n",
    "- Since there seems to be a multicollinearity issue with this model, we decide to scale and center it which lowers the condition number to 15.4 which is not too big of an issue.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b559b3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>9.48e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:11:37</td>     <th>  Log-Likelihood:    </th> <td> -1765.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3624.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   353</td>      <th>  BIC:               </th> <td>   3812.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    46</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>   10.1046</td> <td>   14.957</td> <td>    0.676</td> <td> 0.500</td> <td>  -19.312</td> <td>   39.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>          <td>   -3.2717</td> <td>    4.943</td> <td>   -0.662</td> <td> 0.508</td> <td>  -12.992</td> <td>    6.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>         <td>    9.2938</td> <td>    4.015</td> <td>    2.315</td> <td> 0.021</td> <td>    1.398</td> <td>   17.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>         <td>    2.3150</td> <td>    3.915</td> <td>    0.591</td> <td> 0.555</td> <td>   -5.385</td> <td>   10.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>         <td>    4.8353</td> <td>    4.149</td> <td>    1.165</td> <td> 0.245</td> <td>   -3.325</td> <td>   12.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>         <td>   11.4838</td> <td>    3.960</td> <td>    2.900</td> <td> 0.004</td> <td>    3.696</td> <td>   19.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>         <td>    4.9206</td> <td>    4.746</td> <td>    1.037</td> <td> 0.300</td> <td>   -4.413</td> <td>   14.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Dark]</th>     <td>   -1.4155</td> <td>    6.936</td> <td>   -0.204</td> <td> 0.838</td> <td>  -15.057</td> <td>   12.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Dragon]</th>   <td>    0.8509</td> <td>    6.900</td> <td>    0.123</td> <td> 0.902</td> <td>  -12.720</td> <td>   14.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Electric]</th> <td>   -6.3641</td> <td>    6.537</td> <td>   -0.974</td> <td> 0.331</td> <td>  -19.220</td> <td>    6.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fairy]</th>    <td>   -1.9486</td> <td>   10.124</td> <td>   -0.192</td> <td> 0.847</td> <td>  -21.859</td> <td>   17.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fighting]</th> <td>    7.0308</td> <td>    7.432</td> <td>    0.946</td> <td> 0.345</td> <td>   -7.586</td> <td>   21.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fire]</th>     <td>    3.0779</td> <td>    6.677</td> <td>    0.461</td> <td> 0.645</td> <td>  -10.055</td> <td>   16.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Flying]</th>   <td>   -2.1231</td> <td>   22.322</td> <td>   -0.095</td> <td> 0.924</td> <td>  -46.025</td> <td>   41.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ghost]</th>    <td>    5.7343</td> <td>    8.488</td> <td>    0.676</td> <td> 0.500</td> <td>  -10.960</td> <td>   22.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Grass]</th>    <td>    3.3275</td> <td>    5.496</td> <td>    0.605</td> <td> 0.545</td> <td>   -7.481</td> <td>   14.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ground]</th>   <td>    9.5118</td> <td>    7.076</td> <td>    1.344</td> <td> 0.180</td> <td>   -4.404</td> <td>   23.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ice]</th>      <td>   -0.9313</td> <td>    7.717</td> <td>   -0.121</td> <td> 0.904</td> <td>  -16.108</td> <td>   14.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Normal]</th>   <td>   18.4816</td> <td>    5.312</td> <td>    3.479</td> <td> 0.001</td> <td>    8.034</td> <td>   28.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Poison]</th>   <td>    8.3411</td> <td>    7.735</td> <td>    1.078</td> <td> 0.282</td> <td>   -6.871</td> <td>   23.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Psychic]</th>  <td>    1.8061</td> <td>    6.164</td> <td>    0.293</td> <td> 0.770</td> <td>  -10.317</td> <td>   13.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Rock]</th>     <td>   -3.8558</td> <td>    6.503</td> <td>   -0.593</td> <td> 0.554</td> <td>  -16.645</td> <td>    8.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Steel]</th>    <td>   -4.0053</td> <td>    8.044</td> <td>   -0.498</td> <td> 0.619</td> <td>  -19.826</td> <td>   11.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Water]</th>    <td>    9.7988</td> <td>    5.166</td> <td>    1.897</td> <td> 0.059</td> <td>   -0.361</td> <td>   19.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Dark]</th>     <td>    5.8719</td> <td>   15.185</td> <td>    0.387</td> <td> 0.699</td> <td>  -23.993</td> <td>   35.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Dragon]</th>   <td>   13.2777</td> <td>   14.895</td> <td>    0.891</td> <td> 0.373</td> <td>  -16.016</td> <td>   42.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Electric]</th> <td>   14.3228</td> <td>   17.314</td> <td>    0.827</td> <td> 0.409</td> <td>  -19.728</td> <td>   48.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fairy]</th>    <td>    2.8426</td> <td>   14.268</td> <td>    0.199</td> <td> 0.842</td> <td>  -25.218</td> <td>   30.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fighting]</th> <td>    1.9741</td> <td>   14.089</td> <td>    0.140</td> <td> 0.889</td> <td>  -25.735</td> <td>   29.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fire]</th>     <td>    0.2001</td> <td>   15.730</td> <td>    0.013</td> <td> 0.990</td> <td>  -30.736</td> <td>   31.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Flying]</th>   <td>    6.7292</td> <td>   13.581</td> <td>    0.495</td> <td> 0.621</td> <td>  -19.980</td> <td>   33.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ghost]</th>    <td>  -10.9402</td> <td>   15.895</td> <td>   -0.688</td> <td> 0.492</td> <td>  -42.201</td> <td>   20.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Grass]</th>    <td>    2.5119</td> <td>   14.540</td> <td>    0.173</td> <td> 0.863</td> <td>  -26.084</td> <td>   31.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ground]</th>   <td>   13.6042</td> <td>   13.655</td> <td>    0.996</td> <td> 0.320</td> <td>  -13.250</td> <td>   40.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ice]</th>      <td>   19.7950</td> <td>   15.068</td> <td>    1.314</td> <td> 0.190</td> <td>   -9.840</td> <td>   49.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.None]</th>     <td>    7.6068</td> <td>   13.162</td> <td>    0.578</td> <td> 0.564</td> <td>  -18.279</td> <td>   33.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Normal]</th>   <td>   17.3191</td> <td>   17.764</td> <td>    0.975</td> <td> 0.330</td> <td>  -17.618</td> <td>   52.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Poison]</th>   <td>    0.7770</td> <td>   14.575</td> <td>    0.053</td> <td> 0.958</td> <td>  -27.887</td> <td>   29.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Psychic]</th>  <td>    4.2480</td> <td>   14.174</td> <td>    0.300</td> <td> 0.765</td> <td>  -23.628</td> <td>   32.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Rock]</th>     <td>    6.8858</td> <td>   16.221</td> <td>    0.424</td> <td> 0.671</td> <td>  -25.017</td> <td>   38.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Steel]</th>    <td>  -11.9623</td> <td>   14.973</td> <td>   -0.799</td> <td> 0.425</td> <td>  -41.409</td> <td>   17.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Water]</th>    <td>    5.8097</td> <td>   14.763</td> <td>    0.394</td> <td> 0.694</td> <td>  -23.225</td> <td>   34.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                     <td>    0.2508</td> <td>    0.051</td> <td>    4.940</td> <td> 0.000</td> <td>    0.151</td> <td>    0.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                    <td>   -0.0096</td> <td>    0.060</td> <td>   -0.160</td> <td> 0.873</td> <td>   -0.127</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                      <td>   -0.1538</td> <td>    0.051</td> <td>   -2.998</td> <td> 0.003</td> <td>   -0.255</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>               <td>    0.3484</td> <td>    0.059</td> <td>    5.936</td> <td> 0.000</td> <td>    0.233</td> <td>    0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>               <td>    0.1298</td> <td>    0.051</td> <td>    2.525</td> <td> 0.012</td> <td>    0.029</td> <td>    0.231</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>286.476</td> <th>  Durbin-Watson:     </th> <td>   1.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5187.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.807</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>19.725</td>  <th>  Cond. No.          </th> <td>9.21e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 9.21e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}             &        HP        & \\textbf{  R-squared:         } &     0.392   \\\\\n",
       "\\textbf{Model:}                     &       OLS        & \\textbf{  Adj. R-squared:    } &     0.313   \\\\\n",
       "\\textbf{Method:}                    &  Least Squares   & \\textbf{  F-statistic:       } &     4.948   \\\\\n",
       "\\textbf{Date:}                      & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  9.48e-19   \\\\\n",
       "\\textbf{Time:}                      &     20:11:37     & \\textbf{  Log-Likelihood:    } &   -1765.0   \\\\\n",
       "\\textbf{No. Observations:}          &         400      & \\textbf{  AIC:               } &     3624.   \\\\\n",
       "\\textbf{Df Residuals:}              &         353      & \\textbf{  BIC:               } &     3812.   \\\\\n",
       "\\textbf{Df Model:}                  &          46      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}           &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                    & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                  &      10.1046  &       14.957     &     0.676  &         0.500        &      -19.312    &       39.521     \\\\\n",
       "\\textbf{Legendary[T.True]}          &      -3.2717  &        4.943     &    -0.662  &         0.508        &      -12.992    &        6.449     \\\\\n",
       "\\textbf{C(Generation)[T.2]}         &       9.2938  &        4.015     &     2.315  &         0.021        &        1.398    &       17.189     \\\\\n",
       "\\textbf{C(Generation)[T.3]}         &       2.3150  &        3.915     &     0.591  &         0.555        &       -5.385    &       10.015     \\\\\n",
       "\\textbf{C(Generation)[T.4]}         &       4.8353  &        4.149     &     1.165  &         0.245        &       -3.325    &       12.995     \\\\\n",
       "\\textbf{C(Generation)[T.5]}         &      11.4838  &        3.960     &     2.900  &         0.004        &        3.696    &       19.272     \\\\\n",
       "\\textbf{C(Generation)[T.6]}         &       4.9206  &        4.746     &     1.037  &         0.300        &       -4.413    &       14.254     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Dark]}     &      -1.4155  &        6.936     &    -0.204  &         0.838        &      -15.057    &       12.226     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Dragon]}   &       0.8509  &        6.900     &     0.123  &         0.902        &      -12.720    &       14.422     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Electric]} &      -6.3641  &        6.537     &    -0.974  &         0.331        &      -19.220    &        6.491     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fairy]}    &      -1.9486  &       10.124     &    -0.192  &         0.847        &      -21.859    &       17.962     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fighting]} &       7.0308  &        7.432     &     0.946  &         0.345        &       -7.586    &       21.648     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fire]}     &       3.0779  &        6.677     &     0.461  &         0.645        &      -10.055    &       16.210     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Flying]}   &      -2.1231  &       22.322     &    -0.095  &         0.924        &      -46.025    &       41.779     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ghost]}    &       5.7343  &        8.488     &     0.676  &         0.500        &      -10.960    &       22.429     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Grass]}    &       3.3275  &        5.496     &     0.605  &         0.545        &       -7.481    &       14.136     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ground]}   &       9.5118  &        7.076     &     1.344  &         0.180        &       -4.404    &       23.428     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ice]}      &      -0.9313  &        7.717     &    -0.121  &         0.904        &      -16.108    &       14.246     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Normal]}   &      18.4816  &        5.312     &     3.479  &         0.001        &        8.034    &       28.929     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Poison]}   &       8.3411  &        7.735     &     1.078  &         0.282        &       -6.871    &       23.554     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Psychic]}  &       1.8061  &        6.164     &     0.293  &         0.770        &      -10.317    &       13.930     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Rock]}     &      -3.8558  &        6.503     &    -0.593  &         0.554        &      -16.645    &        8.933     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Steel]}    &      -4.0053  &        8.044     &    -0.498  &         0.619        &      -19.826    &       11.816     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Water]}    &       9.7988  &        5.166     &     1.897  &         0.059        &       -0.361    &       19.959     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Dark]}     &       5.8719  &       15.185     &     0.387  &         0.699        &      -23.993    &       35.737     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Dragon]}   &      13.2777  &       14.895     &     0.891  &         0.373        &      -16.016    &       42.571     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Electric]} &      14.3228  &       17.314     &     0.827  &         0.409        &      -19.728    &       48.374     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fairy]}    &       2.8426  &       14.268     &     0.199  &         0.842        &      -25.218    &       30.903     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fighting]} &       1.9741  &       14.089     &     0.140  &         0.889        &      -25.735    &       29.683     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fire]}     &       0.2001  &       15.730     &     0.013  &         0.990        &      -30.736    &       31.136     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Flying]}   &       6.7292  &       13.581     &     0.495  &         0.621        &      -19.980    &       33.438     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ghost]}    &     -10.9402  &       15.895     &    -0.688  &         0.492        &      -42.201    &       20.321     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Grass]}    &       2.5119  &       14.540     &     0.173  &         0.863        &      -26.084    &       31.108     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ground]}   &      13.6042  &       13.655     &     0.996  &         0.320        &      -13.250    &       40.459     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ice]}      &      19.7950  &       15.068     &     1.314  &         0.190        &       -9.840    &       49.430     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.None]}     &       7.6068  &       13.162     &     0.578  &         0.564        &      -18.279    &       33.493     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Normal]}   &      17.3191  &       17.764     &     0.975  &         0.330        &      -17.618    &       52.256     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Poison]}   &       0.7770  &       14.575     &     0.053  &         0.958        &      -27.887    &       29.441     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Psychic]}  &       4.2480  &       14.174     &     0.300  &         0.765        &      -23.628    &       32.124     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Rock]}     &       6.8858  &       16.221     &     0.424  &         0.671        &      -25.017    &       38.788     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Steel]}    &     -11.9623  &       14.973     &    -0.799  &         0.425        &      -41.409    &       17.485     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Water]}    &       5.8097  &       14.763     &     0.394  &         0.694        &      -23.225    &       34.845     \\\\\n",
       "\\textbf{Attack}                     &       0.2508  &        0.051     &     4.940  &         0.000        &        0.151    &        0.351     \\\\\n",
       "\\textbf{Defense}                    &      -0.0096  &        0.060     &    -0.160  &         0.873        &       -0.127    &        0.108     \\\\\n",
       "\\textbf{Speed}                      &      -0.1538  &        0.051     &    -2.998  &         0.003        &       -0.255    &       -0.053     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}               &       0.3484  &        0.059     &     5.936  &         0.000        &        0.233    &        0.464     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}               &       0.1298  &        0.051     &     2.525  &         0.012        &        0.029    &        0.231     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 286.476 & \\textbf{  Durbin-Watson:     } &    1.917  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5187.327  \\\\\n",
       "\\textbf{Skew:}          &   2.807 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  19.725 & \\textbf{  Cond. No.          } & 9.21e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 9.21e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.392\n",
       "Model:                            OLS   Adj. R-squared:                  0.313\n",
       "Method:                 Least Squares   F-statistic:                     4.948\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           9.48e-19\n",
       "Time:                        20:11:37   Log-Likelihood:                -1765.0\n",
       "No. Observations:                 400   AIC:                             3624.\n",
       "Df Residuals:                     353   BIC:                             3812.\n",
       "Df Model:                          46                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Intercept                     10.1046     14.957      0.676      0.500     -19.312      39.521\n",
       "Legendary[T.True]             -3.2717      4.943     -0.662      0.508     -12.992       6.449\n",
       "C(Generation)[T.2]             9.2938      4.015      2.315      0.021       1.398      17.189\n",
       "C(Generation)[T.3]             2.3150      3.915      0.591      0.555      -5.385      10.015\n",
       "C(Generation)[T.4]             4.8353      4.149      1.165      0.245      -3.325      12.995\n",
       "C(Generation)[T.5]            11.4838      3.960      2.900      0.004       3.696      19.272\n",
       "C(Generation)[T.6]             4.9206      4.746      1.037      0.300      -4.413      14.254\n",
       "C(Q(\"Type 1\"))[T.Dark]        -1.4155      6.936     -0.204      0.838     -15.057      12.226\n",
       "C(Q(\"Type 1\"))[T.Dragon]       0.8509      6.900      0.123      0.902     -12.720      14.422\n",
       "C(Q(\"Type 1\"))[T.Electric]    -6.3641      6.537     -0.974      0.331     -19.220       6.491\n",
       "C(Q(\"Type 1\"))[T.Fairy]       -1.9486     10.124     -0.192      0.847     -21.859      17.962\n",
       "C(Q(\"Type 1\"))[T.Fighting]     7.0308      7.432      0.946      0.345      -7.586      21.648\n",
       "C(Q(\"Type 1\"))[T.Fire]         3.0779      6.677      0.461      0.645     -10.055      16.210\n",
       "C(Q(\"Type 1\"))[T.Flying]      -2.1231     22.322     -0.095      0.924     -46.025      41.779\n",
       "C(Q(\"Type 1\"))[T.Ghost]        5.7343      8.488      0.676      0.500     -10.960      22.429\n",
       "C(Q(\"Type 1\"))[T.Grass]        3.3275      5.496      0.605      0.545      -7.481      14.136\n",
       "C(Q(\"Type 1\"))[T.Ground]       9.5118      7.076      1.344      0.180      -4.404      23.428\n",
       "C(Q(\"Type 1\"))[T.Ice]         -0.9313      7.717     -0.121      0.904     -16.108      14.246\n",
       "C(Q(\"Type 1\"))[T.Normal]      18.4816      5.312      3.479      0.001       8.034      28.929\n",
       "C(Q(\"Type 1\"))[T.Poison]       8.3411      7.735      1.078      0.282      -6.871      23.554\n",
       "C(Q(\"Type 1\"))[T.Psychic]      1.8061      6.164      0.293      0.770     -10.317      13.930\n",
       "C(Q(\"Type 1\"))[T.Rock]        -3.8558      6.503     -0.593      0.554     -16.645       8.933\n",
       "C(Q(\"Type 1\"))[T.Steel]       -4.0053      8.044     -0.498      0.619     -19.826      11.816\n",
       "C(Q(\"Type 1\"))[T.Water]        9.7988      5.166      1.897      0.059      -0.361      19.959\n",
       "C(Q(\"Type 2\"))[T.Dark]         5.8719     15.185      0.387      0.699     -23.993      35.737\n",
       "C(Q(\"Type 2\"))[T.Dragon]      13.2777     14.895      0.891      0.373     -16.016      42.571\n",
       "C(Q(\"Type 2\"))[T.Electric]    14.3228     17.314      0.827      0.409     -19.728      48.374\n",
       "C(Q(\"Type 2\"))[T.Fairy]        2.8426     14.268      0.199      0.842     -25.218      30.903\n",
       "C(Q(\"Type 2\"))[T.Fighting]     1.9741     14.089      0.140      0.889     -25.735      29.683\n",
       "C(Q(\"Type 2\"))[T.Fire]         0.2001     15.730      0.013      0.990     -30.736      31.136\n",
       "C(Q(\"Type 2\"))[T.Flying]       6.7292     13.581      0.495      0.621     -19.980      33.438\n",
       "C(Q(\"Type 2\"))[T.Ghost]      -10.9402     15.895     -0.688      0.492     -42.201      20.321\n",
       "C(Q(\"Type 2\"))[T.Grass]        2.5119     14.540      0.173      0.863     -26.084      31.108\n",
       "C(Q(\"Type 2\"))[T.Ground]      13.6042     13.655      0.996      0.320     -13.250      40.459\n",
       "C(Q(\"Type 2\"))[T.Ice]         19.7950     15.068      1.314      0.190      -9.840      49.430\n",
       "C(Q(\"Type 2\"))[T.None]         7.6068     13.162      0.578      0.564     -18.279      33.493\n",
       "C(Q(\"Type 2\"))[T.Normal]      17.3191     17.764      0.975      0.330     -17.618      52.256\n",
       "C(Q(\"Type 2\"))[T.Poison]       0.7770     14.575      0.053      0.958     -27.887      29.441\n",
       "C(Q(\"Type 2\"))[T.Psychic]      4.2480     14.174      0.300      0.765     -23.628      32.124\n",
       "C(Q(\"Type 2\"))[T.Rock]         6.8858     16.221      0.424      0.671     -25.017      38.788\n",
       "C(Q(\"Type 2\"))[T.Steel]      -11.9623     14.973     -0.799      0.425     -41.409      17.485\n",
       "C(Q(\"Type 2\"))[T.Water]        5.8097     14.763      0.394      0.694     -23.225      34.845\n",
       "Attack                         0.2508      0.051      4.940      0.000       0.151       0.351\n",
       "Defense                       -0.0096      0.060     -0.160      0.873      -0.127       0.108\n",
       "Speed                         -0.1538      0.051     -2.998      0.003      -0.255      -0.053\n",
       "Q(\"Sp. Def\")                   0.3484      0.059      5.936      0.000       0.233       0.464\n",
       "Q(\"Sp. Atk\")                   0.1298      0.051      2.525      0.012       0.029       0.231\n",
       "==============================================================================\n",
       "Omnibus:                      286.476   Durbin-Watson:                   1.917\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5187.327\n",
       "Skew:                           2.807   Prob(JB):                         0.00\n",
       "Kurtosis:                      19.725   Cond. No.                     9.21e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.21e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model5_linear_form = 'HP ~ Attack + Defense + Speed + Legendary'\n",
    "model5_linear_form += ' + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "model5_linear_form += ' + C(Generation) + C(Q(\"Type 1\")) + C(Q(\"Type 2\"))'\n",
    "\n",
    "model5_spec = smf.ols(formula=model5_linear_form, data=pokeaman_train)\n",
    "model5_fit = model5_spec.fit()\n",
    "model5_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "270fb625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3920134083531893\n",
      "'Out of sample' R-squared: 0.30015614488652215\n"
     ]
    }
   ],
   "source": [
    "yhat_model5 = model5_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model5_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model5)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae190de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   24.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>2.25e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:16:38</td>     <th>  Log-Likelihood:    </th> <td> -1783.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3585.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   391</td>      <th>  BIC:               </th> <td>   3621.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                   <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                          <td>   22.8587</td> <td>    3.876</td> <td>    5.897</td> <td> 0.000</td> <td>   15.238</td> <td>   30.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Normal\")[T.True]</th> <td>   17.5594</td> <td>    3.339</td> <td>    5.258</td> <td> 0.000</td> <td>   10.994</td> <td>   24.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Water\")[T.True]</th>  <td>    9.0301</td> <td>    3.172</td> <td>    2.847</td> <td> 0.005</td> <td>    2.794</td> <td>   15.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 2)[T.True]</th>         <td>    6.5293</td> <td>    2.949</td> <td>    2.214</td> <td> 0.027</td> <td>    0.732</td> <td>   12.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 5)[T.True]</th>         <td>    8.4406</td> <td>    2.711</td> <td>    3.114</td> <td> 0.002</td> <td>    3.112</td> <td>   13.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                             <td>    0.2454</td> <td>    0.037</td> <td>    6.639</td> <td> 0.000</td> <td>    0.173</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                              <td>   -0.1370</td> <td>    0.045</td> <td>   -3.028</td> <td> 0.003</td> <td>   -0.226</td> <td>   -0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                       <td>    0.3002</td> <td>    0.045</td> <td>    6.662</td> <td> 0.000</td> <td>    0.212</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                       <td>    0.1192</td> <td>    0.042</td> <td>    2.828</td> <td> 0.005</td> <td>    0.036</td> <td>    0.202</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>271.290</td> <th>  Durbin-Watson:     </th> <td>   1.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4238.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.651</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>18.040</td>  <th>  Cond. No.          </th> <td>    618.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                     &        HP        & \\textbf{  R-squared:         } &     0.333   \\\\\n",
       "\\textbf{Model:}                             &       OLS        & \\textbf{  Adj. R-squared:    } &     0.319   \\\\\n",
       "\\textbf{Method:}                            &  Least Squares   & \\textbf{  F-statistic:       } &     24.36   \\\\\n",
       "\\textbf{Date:}                              & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  2.25e-30   \\\\\n",
       "\\textbf{Time:}                              &     20:16:38     & \\textbf{  Log-Likelihood:    } &   -1783.6   \\\\\n",
       "\\textbf{No. Observations:}                  &         400      & \\textbf{  AIC:               } &     3585.   \\\\\n",
       "\\textbf{Df Residuals:}                      &         391      & \\textbf{  BIC:               } &     3621.   \\\\\n",
       "\\textbf{Df Model:}                          &           8      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                   &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                            & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                          &      22.8587  &        3.876     &     5.897  &         0.000        &       15.238    &       30.479     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Normal\")[T.True]} &      17.5594  &        3.339     &     5.258  &         0.000        &       10.994    &       24.125     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Water\")[T.True]}  &       9.0301  &        3.172     &     2.847  &         0.005        &        2.794    &       15.266     \\\\\n",
       "\\textbf{I(Generation == 2)[T.True]}         &       6.5293  &        2.949     &     2.214  &         0.027        &        0.732    &       12.327     \\\\\n",
       "\\textbf{I(Generation == 5)[T.True]}         &       8.4406  &        2.711     &     3.114  &         0.002        &        3.112    &       13.770     \\\\\n",
       "\\textbf{Attack}                             &       0.2454  &        0.037     &     6.639  &         0.000        &        0.173    &        0.318     \\\\\n",
       "\\textbf{Speed}                              &      -0.1370  &        0.045     &    -3.028  &         0.003        &       -0.226    &       -0.048     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                       &       0.3002  &        0.045     &     6.662  &         0.000        &        0.212    &        0.389     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                       &       0.1192  &        0.042     &     2.828  &         0.005        &        0.036    &        0.202     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 271.290 & \\textbf{  Durbin-Watson:     } &    1.999  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 4238.692  \\\\\n",
       "\\textbf{Skew:}          &   2.651 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  18.040 & \\textbf{  Cond. No.          } &     618.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.333\n",
       "Model:                            OLS   Adj. R-squared:                  0.319\n",
       "Method:                 Least Squares   F-statistic:                     24.36\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           2.25e-30\n",
       "Time:                        20:16:38   Log-Likelihood:                -1783.6\n",
       "No. Observations:                 400   AIC:                             3585.\n",
       "Df Residuals:                     391   BIC:                             3621.\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================================\n",
       "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------\n",
       "Intercept                             22.8587      3.876      5.897      0.000      15.238      30.479\n",
       "I(Q(\"Type 1\") == \"Normal\")[T.True]    17.5594      3.339      5.258      0.000      10.994      24.125\n",
       "I(Q(\"Type 1\") == \"Water\")[T.True]      9.0301      3.172      2.847      0.005       2.794      15.266\n",
       "I(Generation == 2)[T.True]             6.5293      2.949      2.214      0.027       0.732      12.327\n",
       "I(Generation == 5)[T.True]             8.4406      2.711      3.114      0.002       3.112      13.770\n",
       "Attack                                 0.2454      0.037      6.639      0.000       0.173       0.318\n",
       "Speed                                 -0.1370      0.045     -3.028      0.003      -0.226      -0.048\n",
       "Q(\"Sp. Def\")                           0.3002      0.045      6.662      0.000       0.212       0.389\n",
       "Q(\"Sp. Atk\")                           0.1192      0.042      2.828      0.005       0.036       0.202\n",
       "==============================================================================\n",
       "Omnibus:                      271.290   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4238.692\n",
       "Skew:                           2.651   Prob(JB):                         0.00\n",
       "Kurtosis:                      18.040   Cond. No.                         618.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model6_linear_form = 'HP ~ Attack + Speed + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "# And here we'll add the significant indicators from the previous model\n",
    "# https://chatgpt.com/share/81ab88df-4f07-49f9-a44a-de0cfd89c67c\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model6_linear_form += ' + I(Generation==2)'\n",
    "model6_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model6_spec = smf.ols(formula=model6_linear_form, data=pokeaman_train)\n",
    "model6_fit = model6_spec.fit()\n",
    "model6_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00d00788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908\n",
      "'Out of sample' R-squared: 0.29572460427079933\n"
     ]
    }
   ],
   "source": [
    "yhat_model6 = model6_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bde4ce5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.20e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:30:21</td>     <th>  Log-Likelihood:    </th> <td> -1769.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3579.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   380</td>      <th>  BIC:               </th> <td>   3659.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                     <td></td>                       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                              <td>   95.1698</td> <td>   34.781</td> <td>    2.736</td> <td> 0.007</td> <td>   26.783</td> <td>  163.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Normal\")[T.True]</th>     <td>   18.3653</td> <td>    3.373</td> <td>    5.445</td> <td> 0.000</td> <td>   11.733</td> <td>   24.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Water\")[T.True]</th>      <td>    9.2913</td> <td>    3.140</td> <td>    2.959</td> <td> 0.003</td> <td>    3.117</td> <td>   15.466</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 2)[T.True]</th>             <td>    7.0711</td> <td>    2.950</td> <td>    2.397</td> <td> 0.017</td> <td>    1.271</td> <td>   12.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 5)[T.True]</th>             <td>    7.8557</td> <td>    2.687</td> <td>    2.923</td> <td> 0.004</td> <td>    2.572</td> <td>   13.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                 <td>   -0.6975</td> <td>    0.458</td> <td>   -1.523</td> <td> 0.129</td> <td>   -1.598</td> <td>    0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                  <td>   -1.8147</td> <td>    0.554</td> <td>   -3.274</td> <td> 0.001</td> <td>   -2.905</td> <td>   -0.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                           <td>    0.0189</td> <td>    0.007</td> <td>    2.882</td> <td> 0.004</td> <td>    0.006</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                           <td>   -0.5532</td> <td>    0.546</td> <td>   -1.013</td> <td> 0.312</td> <td>   -1.627</td> <td>    0.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                    <td>    0.0090</td> <td>    0.007</td> <td>    1.311</td> <td> 0.191</td> <td>   -0.004</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                     <td>    0.0208</td> <td>    0.008</td> <td>    2.571</td> <td> 0.011</td> <td>    0.005</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>              <td>   -0.0002</td> <td> 9.06e-05</td> <td>   -2.277</td> <td> 0.023</td> <td>   -0.000</td> <td>-2.82e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                           <td>   -0.7277</td> <td>    0.506</td> <td>   -1.439</td> <td> 0.151</td> <td>   -1.722</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                    <td>    0.0136</td> <td>    0.005</td> <td>    2.682</td> <td> 0.008</td> <td>    0.004</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                     <td>    0.0146</td> <td>    0.007</td> <td>    2.139</td> <td> 0.033</td> <td>    0.001</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>              <td>   -0.0002</td> <td>  5.4e-05</td> <td>   -3.383</td> <td> 0.001</td> <td>   -0.000</td> <td>-7.65e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0103</td> <td>    0.007</td> <td>    1.516</td> <td> 0.130</td> <td>   -0.003</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>   -0.0001</td> <td> 6.71e-05</td> <td>   -2.119</td> <td> 0.035</td> <td>   -0.000</td> <td>-1.03e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0002</td> <td> 8.82e-05</td> <td>   -2.075</td> <td> 0.039</td> <td>   -0.000</td> <td>-9.62e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>  2.03e-06</td> <td> 7.42e-07</td> <td>    2.734</td> <td> 0.007</td> <td>  5.7e-07</td> <td> 3.49e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>2.34e+09</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.34e+09. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                         &        HP        & \\textbf{  R-squared:         } &     0.378   \\\\\n",
       "\\textbf{Model:}                                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.347   \\\\\n",
       "\\textbf{Method:}                                &  Least Squares   & \\textbf{  F-statistic:       } &     12.16   \\\\\n",
       "\\textbf{Date:}                                  & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.20e-29   \\\\\n",
       "\\textbf{Time:}                                  &     20:30:21     & \\textbf{  Log-Likelihood:    } &   -1769.5   \\\\\n",
       "\\textbf{No. Observations:}                      &         400      & \\textbf{  AIC:               } &     3579.   \\\\\n",
       "\\textbf{Df Residuals:}                          &         380      & \\textbf{  BIC:               } &     3659.   \\\\\n",
       "\\textbf{Df Model:}                              &          19      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                              &      95.1698  &       34.781     &     2.736  &         0.007        &       26.783    &      163.556     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Normal\")[T.True]}     &      18.3653  &        3.373     &     5.445  &         0.000        &       11.733    &       24.997     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Water\")[T.True]}      &       9.2913  &        3.140     &     2.959  &         0.003        &        3.117    &       15.466     \\\\\n",
       "\\textbf{I(Generation == 2)[T.True]}             &       7.0711  &        2.950     &     2.397  &         0.017        &        1.271    &       12.871     \\\\\n",
       "\\textbf{I(Generation == 5)[T.True]}             &       7.8557  &        2.687     &     2.923  &         0.004        &        2.572    &       13.140     \\\\\n",
       "\\textbf{Attack}                                 &      -0.6975  &        0.458     &    -1.523  &         0.129        &       -1.598    &        0.203     \\\\\n",
       "\\textbf{Speed}                                  &      -1.8147  &        0.554     &    -3.274  &         0.001        &       -2.905    &       -0.725     \\\\\n",
       "\\textbf{Attack:Speed}                           &       0.0189  &        0.007     &     2.882  &         0.004        &        0.006    &        0.032     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                           &      -0.5532  &        0.546     &    -1.013  &         0.312        &       -1.627    &        0.521     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                    &       0.0090  &        0.007     &     1.311  &         0.191        &       -0.004    &        0.023     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                     &       0.0208  &        0.008     &     2.571  &         0.011        &        0.005    &        0.037     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}              &      -0.0002  &     9.06e-05     &    -2.277  &         0.023        &       -0.000    &    -2.82e-05     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                           &      -0.7277  &        0.506     &    -1.439  &         0.151        &       -1.722    &        0.267     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                    &       0.0136  &        0.005     &     2.682  &         0.008        &        0.004    &        0.024     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                     &       0.0146  &        0.007     &     2.139  &         0.033        &        0.001    &        0.028     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}              &      -0.0002  &      5.4e-05     &    -3.383  &         0.001        &       -0.000    &    -7.65e-05     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0103  &        0.007     &     1.516  &         0.130        &       -0.003    &        0.024     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &      -0.0001  &     6.71e-05     &    -2.119  &         0.035        &       -0.000    &    -1.03e-05     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0002  &     8.82e-05     &    -2.075  &         0.039        &       -0.000    &    -9.62e-06     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &     2.03e-06  &     7.42e-07     &     2.734  &         0.007        &      5.7e-07    &     3.49e-06     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } & 2.34e+09  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.34e+09. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.378\n",
       "Model:                            OLS   Adj. R-squared:                  0.347\n",
       "Method:                 Least Squares   F-statistic:                     12.16\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           4.20e-29\n",
       "Time:                        20:30:21   Log-Likelihood:                -1769.5\n",
       "No. Observations:                 400   AIC:                             3579.\n",
       "Df Residuals:                     380   BIC:                             3659.\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================================\n",
       "                                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------------\n",
       "Intercept                                 95.1698     34.781      2.736      0.007      26.783     163.556\n",
       "I(Q(\"Type 1\") == \"Normal\")[T.True]        18.3653      3.373      5.445      0.000      11.733      24.997\n",
       "I(Q(\"Type 1\") == \"Water\")[T.True]          9.2913      3.140      2.959      0.003       3.117      15.466\n",
       "I(Generation == 2)[T.True]                 7.0711      2.950      2.397      0.017       1.271      12.871\n",
       "I(Generation == 5)[T.True]                 7.8557      2.687      2.923      0.004       2.572      13.140\n",
       "Attack                                    -0.6975      0.458     -1.523      0.129      -1.598       0.203\n",
       "Speed                                     -1.8147      0.554     -3.274      0.001      -2.905      -0.725\n",
       "Attack:Speed                               0.0189      0.007      2.882      0.004       0.006       0.032\n",
       "Q(\"Sp. Def\")                              -0.5532      0.546     -1.013      0.312      -1.627       0.521\n",
       "Attack:Q(\"Sp. Def\")                        0.0090      0.007      1.311      0.191      -0.004       0.023\n",
       "Speed:Q(\"Sp. Def\")                         0.0208      0.008      2.571      0.011       0.005       0.037\n",
       "Attack:Speed:Q(\"Sp. Def\")                 -0.0002   9.06e-05     -2.277      0.023      -0.000   -2.82e-05\n",
       "Q(\"Sp. Atk\")                              -0.7277      0.506     -1.439      0.151      -1.722       0.267\n",
       "Attack:Q(\"Sp. Atk\")                        0.0136      0.005      2.682      0.008       0.004       0.024\n",
       "Speed:Q(\"Sp. Atk\")                         0.0146      0.007      2.139      0.033       0.001       0.028\n",
       "Attack:Speed:Q(\"Sp. Atk\")                 -0.0002    5.4e-05     -3.383      0.001      -0.000   -7.65e-05\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0103      0.007      1.516      0.130      -0.003       0.024\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          -0.0001   6.71e-05     -2.119      0.035      -0.000   -1.03e-05\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0002   8.82e-05     -2.075      0.039      -0.000   -9.62e-06\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")   2.03e-06   7.42e-07      2.734      0.007     5.7e-07    3.49e-06\n",
       "==============================================================================\n",
       "Omnibus:                      252.300   Durbin-Watson:                   1.953\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3474.611\n",
       "Skew:                           2.438   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.590   Cond. No.                     2.34e+09\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.34e+09. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here's a slight change that seems to perhaps improve prediction...\n",
    "model7_linear_form = 'HP ~ Attack * Speed * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form += ' + I(Generation==2)'\n",
    "model7_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model7_spec = smf.ols(formula=model7_linear_form, data=pokeaman_train)\n",
    "model7_fit = model7_spec.fit()\n",
    "model7_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f830d6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456\n",
      "'Out of sample' R-squared: 0.35055389205977444\n"
     ]
    }
   ],
   "source": [
    "yhat_model7 = model7_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4e276e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>    15.4</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } &     15.4  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here's a slight change that seems to perhas improve prediction...\n",
    "model7_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Speed))'\n",
    "model7_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# We DO NOT center and scale indicator variables\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form_CS += ' + I(Generation==2)'\n",
    "model7_linear_form_CS += ' + I(Generation==5)'\n",
    "\n",
    "model7_CS_spec = smf.ols(formula=model7_linear_form_CS, data=pokeaman_train)\n",
    "model7_CS_fit = model7_CS_spec.fit()\n",
    "model7_CS_fit.summary().tables[-1] \n",
    "# \"Cond. No.\" is NOW 15.4 due to centering and scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d9940c",
   "metadata": {},
   "source": [
    "## Q8\n",
    "##### GPT: https://chatgpt.com/share/6736651d-223c-8008-b968-82ee31b253df\n",
    "- I used pokeaman dataset at linear form 'Attack ~ Defense + Q(\"Sp. Atk\") + Q(\"Sp. Def\") + Speed' as an example\n",
    "- For 100 times, we split do a 50% train-test split\n",
    "    - Then we fit a model on the training data\n",
    "    - We record the in-sample $R^2$ by using the fitted model\n",
    "    - For out of sample $R^2$ we calculate the correlation squared on the testing data.\n",
    "    - Then we store those values\n",
    "- Then we plot those points with independent variable as in-sample and dependent as out of sample\n",
    "- Then I fit a line \n",
    "\n",
    "Purpose:\n",
    "- Shows variance in model performance when it has different testing/training data\n",
    "- By comparing in-sample and out of sample data performane we can assess the model's ability to generalize, which it seems it does\n",
    "- It can help us know if the model consistently reproduces new and unseen data which will let us know if it is reliable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "36a82e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Assuming pokeaman data is already loaded\n",
    "fifty_fifty_split_size = int(pokeaman.shape[0]*0.5)\n",
    "\n",
    "# Replace \"NaN\" (in the \"Type 2\" column with \"None\")\n",
    "pokeaman.fillna('None', inplace=True)\n",
    "\n",
    "# Set up for repeated simulations\n",
    "reps = 100  # Number of iterations\n",
    "in_sample_Rsquared = np.array([0.0]*reps)\n",
    "out_of_sample_Rsquared = np.array([0.0]*reps)\n",
    "\n",
    "# Specify a linear model formula, for example, predicting \"Attack\" based on \"Defense\" and other features\n",
    "# Modify the formula as per your data and analysis needs.\n",
    "linear_form = 'Attack ~ Defense + Q(\"Sp. Atk\") + Q(\"Sp. Def\") + Speed'\n",
    "\n",
    "for i in range(reps):\n",
    "    # Split the data into training and testing sets (50-50 split)\n",
    "    pokeaman_train, pokeaman_test = train_test_split(pokeaman, train_size=fifty_fifty_split_size)\n",
    "\n",
    "    # Fit the model on the training data\n",
    "    final_model_fit = smf.ols(formula=linear_form, data=pokeaman_train).fit()\n",
    "    \n",
    "    # Record the R-squared for in-sample performance\n",
    "    in_sample_Rsquared[i] = final_model_fit.rsquared\n",
    "    \n",
    "    # For out-of-sample performance, use the test set\n",
    "    # Compute the R-squared for predictions on the test set\n",
    "    out_of_sample_Rsquared[i] = np.corrcoef(pokeaman_test['Attack'], final_model_fit.predict(pokeaman_test))[0,1]**2\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "df = pd.DataFrame({\n",
    "    \"In Sample Performance (Rsquared)\": in_sample_Rsquared,\n",
    "    \"Out of Sample Performance (Rsquared)\": out_of_sample_Rsquared\n",
    "})\n",
    "\n",
    "# Plot the results\n",
    "fig = px.scatter(df, x=\"In Sample Performance (Rsquared)\", y=\"Out of Sample Performance (Rsquared)\")\n",
    "\n",
    "X = df[\"In Sample Performance (Rsquared)\"].values.reshape(-1, 1)\n",
    "y = df[\"Out of Sample Performance (Rsquared)\"].values\n",
    "\n",
    "# Fit a linear regression model\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X, y)\n",
    "\n",
    "# Predict the fitted values\n",
    "y_pred = regressor.predict(X)\n",
    "\n",
    "# Add the fitted line to the plot\n",
    "fig.add_trace(go.Scatter(x=df[\"In Sample Performance (Rsquared)\"], \n",
    "                         y=y_pred, \n",
    "                         mode='lines', \n",
    "                         name=\"Fitted Line\", \n",
    "                         line=dict(color='red', dash='dash')))\n",
    "\n",
    "fig.show(renderer='png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe46f661",
   "metadata": {},
   "source": [
    "## Q9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210997c6",
   "metadata": {},
   "source": [
    "##### GPT: https://chatgpt.com/share/673691c0-f69c-8008-97a2-44267c4e9b22\n",
    "\n",
    "- Overall this illustrates the trade off between generalization and complexity\n",
    "- With a more complex formula (model 7), we are left with a weaker ability to generalize as seen with the R-squared values. \n",
    "- With a less complex formula we see that overall the models generalize better and is more reliable, however we have do not have interactions that may be interesting factor to the outcome.\n",
    "- Formulas with greater complexity may be prone to overfitting which means simpler formulas are a safer choice overall. Plus, simpler models are easier to interpret.\n",
    "- By training with different generations we see that whether removing generations affects the ability to explain the variability. It seems like the narrower the training data is, the more accurate the predictions are for the in sample, but the but less accurate for the out of sample (new data) and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7524538a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456 (original)\n",
      "'Out of sample' R-squared: 0.0017343562547700454 (original)\n",
      "'In sample' R-squared:     0.5726118179916575 (gen1_predict_future)\n",
      "'Out of sample' R-squared: 0.11151363354803218 (gen1_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model7_gen1_predict_future = smf.ols(formula=model7_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation==1])\n",
    "model7_gen1_predict_future_fit = model7_gen1_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model7_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation!=1].HP\n",
    "yhat = model7_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation!=1])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1_predict_future)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2d988b",
   "metadata": {},
   "source": [
    "- Uses formula model7_linear_form which has interactions of 4 predictors and indicator variables.\n",
    "- Shows that generation 1 specific model has better in sample and out of sample R-squared.\n",
    "- Out of sample R-squared is still not that strong.\n",
    "- Generation 1 model is overfitting and does not generalize well with Pokemon from other generations (ie predictions are not reliable since it only explains 11% of the variation)\n",
    "- Both models seem to have overfitting and poor generalization, although the generation 1 model seems a bit better than the latter, but we definitely need further improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4558ab65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456 (original)\n",
      "'Out of sample' R-squared: 0.0017343562547700454 (original)\n",
      "'In sample' R-squared:     0.3904756578094535 (gen1to5_predict_future)\n",
      "'Out of sample' R-squared: 0.23394915464343125 (gen1to5_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model7_gen1to5_predict_future = smf.ols(formula=model7_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation!=6])\n",
    "model7_gen1to5_predict_future_fit = model7_gen1to5_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model7_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation==6].HP\n",
    "yhat = model7_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation==6])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1to5_predict_future)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098d8012",
   "metadata": {},
   "source": [
    "- Sample formula as above\n",
    "- Slightly better results.\n",
    "- Data is from generations 1 to 5 now\n",
    "- Original data has same in sample and out of sapmle R-squared\n",
    "- Model trained on generation 1-5 \n",
    "- Now since the gen1to5 in sample R-squared illustrates that the model trained on gen1to5 better explains the variance compared to the original\n",
    "- Our out of sample R-squared is now 0.233 which is much better than out of sample R-squared for just generation 1 predictions\n",
    "- Now for the in sample performance, this shows us that removing generation 6 does not significantly affect the model's ability to fit training data.\n",
    "- For the out of sample performance, this shows that the model trained on gen 1 to 5 is much better for future predictions, which includes gen 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b3835721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908 (original)\n",
      "'Out of sample' R-squared: 0.002106169131189054 (original)\n",
      "'In sample' R-squared:     0.4433880517727282 (gen1_predict_future)\n",
      "'Out of sample' R-squared: 0.1932858534276128 (gen1_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model6_gen1_predict_future = smf.ols(formula=model6_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation==1])\n",
    "model6_gen1_predict_future_fit = model6_gen1_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model6_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation!=1].HP\n",
    "yhat = model6_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation!=1])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1_predict_future)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d27fd9",
   "metadata": {},
   "source": [
    "- Now, we only use gen 1 to predict other generations but now we use a formula that does not have interactions between predictors.\n",
    "- In this scenario we see that there is a greater improvement.\n",
    "- Original model in-sample explains 33% of the variation\n",
    "- Original model out of sample fails to generalize to the testing set since it does not explain variation well at all\n",
    "- Now the greater in sample r-squared for generation 1 model shows it is a better fit than the original as it explains more of the variation. Since it is tailored to one generation it has more opportunity to explain variation since it's one type.\n",
    "- THe out of sample r-squared for the generation 1 model explains 19% of the variation which indicated that it is able to predict HP for other generations but it is still not strong.\n",
    "\n",
    "- Unlike the original one that used model7 as the formula, the out of sample predictions are a bit better since it is difficult to generalize interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "92d6eede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908 (original)\n",
      "'Out of sample' R-squared: 0.002106169131189054 (original)\n",
      "'In sample' R-squared:     0.33517279824114776 (gen1to5_predict_future)\n",
      "'Out of sample' R-squared: 0.26262690178799936 (gen1to5_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model6_gen1to5_predict_future = smf.ols(formula=model6_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation!=6])\n",
    "model6_gen1to5_predict_future_fit = model6_gen1to5_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model6_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation==6].HP\n",
    "yhat = model6_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation==6])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1to5_predict_future)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8a9ac5",
   "metadata": {},
   "source": [
    "- Like before, this uses a less complex formula with no interactions\n",
    "- We can see the original model has same in and out of sample r-squared\n",
    "- However, for now we change it to training with data from gen1-5. \n",
    "- We can see that the gen1to5 training data has a greater r-squared than the original, mostly because we narrow down our data.\n",
    "- However, the out of sample has an large increase which may mean that gen1to5 can predict gen6 HP, although not as well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
